{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b72684a-6f1b-410e-9ddb-1210e0532aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_squared_error, f1_score, roc_auc_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875a6d9c-2a2b-4982-acfa-5d446c2997ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "shop = pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "\n",
    "# reading in the file, assigning boolean and numeric variables, and dropping NaN values\n",
    "shop['Weekend'] = shop['Weekend'].map({False: 0, True: 1})\n",
    "shop['Revenue'] = shop['Revenue'].map({False: 0, True: 1})\n",
    "shop['Month'] = shop['Month'].map({'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12})\n",
    "shop['VisitorType'] = shop['VisitorType'].map({'Returning_Visitor': 1, 'New_Visitor': 0})\n",
    "shop.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3fb053-d9eb-4bec-8f77-dbb8d8ca3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating data into dependent and independent variables\n",
    "Y = shop['Revenue']\n",
    "shop.drop(['Revenue'], axis = 1, inplace = True)\n",
    "X = shop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530b66a-4e2f-4e7c-b31d-7d50ee40b0dc",
   "metadata": {},
   "source": [
    "<h1> Decision Tree Classifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb39e26b-aa72-4729-a79f-f5705630da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree(X,Y, scoring = True, heatmap = False):\n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    clf = DecisionTreeClassifier()\n",
    "\n",
    "    # set hyperparameters grid\n",
    "    param_grid = {'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                  'max_depth': [i for i in range(5)],\n",
    "                  'min_samples_split': [2,5,10,20]}\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid)           \n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # finding best parameters\n",
    "    new_param = grid_search.best_params_\n",
    "    for item, key in new_param.items():\n",
    "            new_param[item] = [key]\n",
    "\n",
    "    # making predictions\n",
    "    final_clf = GridSearchCV(clf, new_param)\n",
    "    final_clf.fit(x_train, y_train)\n",
    "    predictions = final_clf.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing model and scores\n",
    "    model = \"Decision Tree\"\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "    \n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Purchases Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "        \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023400c8-0b18-4b01-9665-e8aaad2bbe2b",
   "metadata": {},
   "source": [
    "<h1> Random Forest Classifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "154857c2-3a76-4794-bf2a-8ebe05d11ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(X,Y, scoring = True, heatmap = False):\n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    clf = RandomForestClassifier()\n",
    "        \n",
    "    # set hyperparameters grid\n",
    "    param_grid = {'n_estimators': [10,50,100,200],\n",
    "                  'max_depth': [i for i in range(5)],\n",
    "                  'min_samples_split': [2,5,10,20]}\n",
    "\n",
    "    grid_search = GridSearchCV(clf, param_grid)           \n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # finding best parameters\n",
    "    new_param = grid_search.best_params_\n",
    "    for item, key in new_param.items():\n",
    "            new_param[item] = [key]\n",
    "\n",
    "    # making predictions\n",
    "    final_clf = GridSearchCV(clf, new_param)\n",
    "    final_clf.fit(x_train, y_train)\n",
    "    predictions = final_clf.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'Random Forest'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "    \n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff83086-53cd-45c9-a124-f56b126c9ae1",
   "metadata": {},
   "source": [
    "<h1> Logistic Regression </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b82cda-fb22-49b2-8da1-ef8f6c2180ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regr(X,Y, scoring = True, heatmap = False):  \n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    logisticRegr = LogisticRegression()\n",
    "    logisticRegr.fit(x_train, y_train)\n",
    "    predictions = logisticRegr.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'Logistic Regression'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "\n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567fae2-0088-4611-8e8d-d93bcec7be79",
   "metadata": {},
   "source": [
    "<h1> KNeighbors Classifier </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34aad4db-6e2c-49ce-a698-b88c243f8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(X,Y, scoring = True, heatmap = False):\n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    predictions = knn.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'K-Nearest Neighbors'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "\n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c9cf9-6d60-4b86-973f-57ab1faa9c93",
   "metadata": {},
   "source": [
    "<h1> Gaussian Naive Bayes </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f18e37-8534-44d0-9281-b16cd7301994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gnb(X,Y, scoring = True, heatmap = False):\n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(x_train, y_train)\n",
    "    predictions = gnb.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'Gaussian Naive Bayes'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "\n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e776f81-f01b-47db-b909-10afd33deb80",
   "metadata": {},
   "source": [
    "<h1> Stochastic Gradient Descent </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9db74cb4-ac3d-4941-983a-6f203fa6070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sgd(X,Y, scoring = True, heatmap = False):\n",
    "   \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(x_train, y_train)\n",
    "    predictions = clf.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'Stochastic Gradient Descent'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "\n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ecf394-369c-4b0a-bab8-c96b1db3ba70",
   "metadata": {},
   "source": [
    "<h1> Support Vector Classification </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52e970e4-c288-44ba-9a78-15206a638f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svc(X,Y, scoring = True, heatmap = False):\n",
    "    \n",
    "    # split the data into training/test\n",
    "    x_train, x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)\n",
    "    \n",
    "    # initialize classification object\n",
    "    clf = SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    predictions = clf.predict(x_test)\n",
    "    predictions2 = list(predictions)\n",
    "    \n",
    "    # finding recall for purchases\n",
    "    correct_preds = []\n",
    "    for i in range(len(predictions2)):\n",
    "        if predictions2[i] == 1 and predictions2[i] == list(y_test)[i]:\n",
    "            correct_preds.append(predictions2[i])\n",
    "\n",
    "    # storing models and scores\n",
    "    model = 'Support Vector'\n",
    "    score_recall = round((sum(correct_preds)/sum(y_test)),3)\n",
    "    f1_scores = round(f1_score(y_test, predictions),3)\n",
    "\n",
    "    if heatmap == True:\n",
    "        # heatmap plot to visualize predictions\n",
    "        cm = metrics.confusion_matrix(y_test, predictions)\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(cm, annot = True, fmt = \".0f\", square = True, cmap = 'icefire');\n",
    "        plt.ylabel('Actual Label');\n",
    "        plt.xlabel('Predicted Label');\n",
    "        all_sample_title = f'{model} \\n F1 {f1_scores} \\n Recall: {score_recall}'\n",
    "        plt.title(all_sample_title, size = 20);\n",
    "    \n",
    "    if scoring == True:\n",
    "        return model, score_recall, f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c364aa28-e886-4f57-8775-5edc4fa99bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(X,Y):\n",
    "    # initialize lists to store scores in\n",
    "    models = []\n",
    "    f1s = []\n",
    "    recalls = []\n",
    "    \n",
    "    # list of all models/corresponding functions\n",
    "    model_function_names = [run_decision_tree, run_random_forest, run_logistic_regr, \n",
    "                           run_knn, run_gnb, run_sgd, run_svc]\n",
    "    \n",
    "    # run each model, record scores\n",
    "    for name in model_function_names:\n",
    "        model_name, recall, f1 = name(X,Y)\n",
    "        models.append(model_name)\n",
    "        f1s.append(f1)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    # report scores as a dataframe\n",
    "    scores = {'Classification Model': models, 'F1 Score': f1s, 'Recall Score': recalls}\n",
    "    return pd.DataFrame.from_dict(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcc46b3b-cce6-4d8c-8548-b5ab500c308d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classification Model  F1 Score  Recall Score\n",
       "0                Decision Tree     0.655         0.667\n",
       "1                Random Forest     0.467         0.326\n",
       "2          Logistic Regression     0.464         0.338\n",
       "3          K-Nearest Neighbors     0.363         0.265\n",
       "4         Gaussian Naive Bayes     0.521         0.542\n",
       "5  Stochastic Gradient Descent     0.355         0.921\n",
       "6               Support Vector     0.006         0.003"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running all models\n",
    "scores_df = run_all(X,Y)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58f58d9-70d4-49b3-be82-7d704766fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_one(model, n, X,Y):\n",
    "\n",
    "    # storing scores for model\n",
    "    f1s = []\n",
    "    recalls = []\n",
    "    \n",
    "    # running model n times to see consistency of scores\n",
    "    for i in range(n):\n",
    "        model_name, recall, f1 = model(X,Y)\n",
    "        f1s.append(f1)\n",
    "        recalls.append(recall)\n",
    "        \n",
    "    # storing scores as a dataframe\n",
    "    scores = {'F1 Score': f1s, 'Recall Score': recalls}\n",
    "    return pd.DataFrame.from_dict(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4932d3d-bf82-44c7-8722-a36c91911fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' uncomment to see average scores for multiple runs per model '''\n",
    "# model_function_names = [run_decision_tree, run_random_forest, run_logistic_regr, \n",
    "#                           run_knn, run_gnb, run_sgd, run_svc]\n",
    "#for name in model_function_names:\n",
    "#    print(name)\n",
    "#    print(run_one(name, 5, X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c456bc-18d5-43bb-bfec-454351b26da8",
   "metadata": {},
   "source": [
    "<h1> Expirementing with Training Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bedc3b1e-dbc6-4e4a-9c42-1c75b980e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in file, following same cleaning process above\n",
    "shop2 = pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "shop2['Weekend'] = shop2['Weekend'].map({False: 0, True: 1})\n",
    "shop2['Revenue'] = shop2['Revenue'].map({False: 0, True: 1})\n",
    "shop2['Month'] = shop2['Month'].map({'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6, 'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12})\n",
    "shop2['VisitorType'] = shop2['VisitorType'].map({'Returning_Visitor': 1, 'New_Visitor': 0})\n",
    "shop2.dropna(inplace = True)\n",
    "\n",
    "# separating data into purchases, assinging equal proportions of purchases to non-purchases\n",
    "purchases = shop2[shop2['Revenue'] == 1]\n",
    "non_purchases = shop2[shop2['Revenue'] == 0].sample(n = len(purchases))\n",
    "new_data = pd.concat([purchases, non_purchases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02a73d67-ea78-40b3-8ebd-56c784c9a283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating into independent and dependent variables\n",
    "new_Y = shop2['Revenue']\n",
    "shop2.drop(['Revenue'], axis = 1, inplace = True)\n",
    "new_X = shop2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "396275a5-e8af-46b1-aff2-1ced8a1b3f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classification Model  F1 Score  Recall Score\n",
       "0                Decision Tree     0.665         0.621\n",
       "1                Random Forest     0.455         0.309\n",
       "2          Logistic Regression     0.501         0.388\n",
       "3          K-Nearest Neighbors     0.390         0.289\n",
       "4         Gaussian Naive Bayes     0.538         0.554\n",
       "5  Stochastic Gradient Descent     0.341         0.219\n",
       "6               Support Vector     0.026         0.013"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing scores with adjusted training data\n",
    "new_df = run_all(new_X, new_Y)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2d6c48-d68c-4aad-aeed-b44051943049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classification Model</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Recall Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Classification Model  F1 Score  Recall Score\n",
       "0                Decision Tree     0.655         0.667\n",
       "1                Random Forest     0.467         0.326\n",
       "2          Logistic Regression     0.464         0.338\n",
       "3          K-Nearest Neighbors     0.363         0.265\n",
       "4         Gaussian Naive Bayes     0.521         0.542\n",
       "5  Stochastic Gradient Descent     0.355         0.921\n",
       "6               Support Vector     0.006         0.003"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original training data scores\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a12d835-0f41-4daf-bd75-307e5aa989d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
